download_extract() |>
read_ipums_micro()
# remove rows where WHYMOVE is 0
# and MIGSTA1 is not 91 or 99
# delete columns that are not WHYMOVE and MIGSTA1
data_movers_only <- data |>
filter(WHYMOVE != 0) |>
filter(MIGRATE1 == 5) |>
filter(!(MIGSTA1 == 91 | MIGSTA1 == 99)) |>
select(YEAR, WHYMOVE, MIGSTA1)
View(data)
View(data_movers_only)
# Create a dictionary for "Reason for moving"
reason_for_moving_dict <- list(
`0` = "NIU",
`1` = "Change in marital status",
`2` = "To establish own household",
`3` = "Other family reason",
`4` = "New job or job transfer",
`5` = "To look for work or lost job",
`6` = "For easier commute",
`7` = "Retired",
`8` = "Other job-related reason",
`9` = "Wanted to own home, not rent",
`10` = "Wanted new or better housing",
`11` = "Wanted better neighborhood",
`12` = "For cheaper housing",
`13` = "Other housing reason",
`14` = "Attend/leave college",
`15` = "Change of climate",
`16` = "Health reasons",
`17` = "Other reasons",
`18` = "Natural disaster",
`19` = "Foreclosure or eviction",
`20` = "Relationship with unmarried partner"
)
# Create a dictionary for "State of residence 1 year ago"
state_residence_dict <- list(
`0` = "NIU",
`1` = "Alabama",
`2` = "Alaska",
`4` = "Arizona",
`5` = "Arkansas",
`6` = "California",
`8` = "Colorado",
`9` = "Connecticut",
`10` = "Delaware",
`11` = "District of Columbia",
`12` = "Florida",
`13` = "Georgia",
`15` = "Hawaii",
`16` = "Idaho",
`17` = "Illinois",
`18` = "Indiana",
`19` = "Iowa",
`20` = "Kansas",
`21` = "Kentucky",
`22` = "Louisiana",
`23` = "Maine",
`24` = "Maryland",
`25` = "Massachusetts",
`26` = "Michigan",
`27` = "Minnesota",
`28` = "Mississippi",
`29` = "Missouri",
`30` = "Montana",
`31` = "Nebraska",
`32` = "Nevada",
`33` = "New Hampshire",
`34` = "New Jersey",
`35` = "New Mexico",
`36` = "New York",
`37` = "North Carolina",
`38` = "North Dakota",
`39` = "Ohio",
`40` = "Oklahoma",
`41` = "Oregon",
`42` = "Pennsylvania",
`44` = "Rhode Island",
`45` = "South Carolina",
`46` = "South Dakota",
`47` = "Tennessee",
`48` = "Texas",
`49` = "Utah",
`50` = "Vermont",
`51` = "Virginia",
`53` = "Washington",
`54` = "West Virginia",
`55` = "Wisconsin",
`56` = "Wyoming",
`91` = "Abroad",
`99` = "Same house"
)
# Replace numeric codes with labels in the dataset
data_movers_only$WHYMOVE <- reason_for_moving_dict[as.character(data_movers_only$WHYMOVE)]
data_movers_only$MIGSTA1 <- state_residence_dict[as.character(data_movers_only$MIGSTA1)]
data_movers_only$YEAR <- as.character(data_movers_only$YEAR)
data_movers_only$MIGSTA1 <- as.character(data_movers_only$MIGSTA1)
data_movers_only$WHYMOVE <- as.character(data_movers_only$WHYMOVE)
write_csv(data, "./raw data/moving_reason_by_state_raw.csv")
write_csv(data_movers_only, "./cleansed data/moving_reason_by_state.csv")
as.factor(data$WHYMOVE)
have::as.factor(data$WHYMOVE)
haven::as.factor(data$WHYMOVE)
haven::as_factor(data$WHYMOVE)
ggplot(data_movers_only, aes(x = WHYMOVE)) +
geom_bar() +
labs(title = "Reason for Moving to Another State",
x = "Reason",
y = "Count")
library(ipumsr)
library(tidyverse)
ggplot(data_movers_only, aes(x = WHYMOVE)) +
geom_bar() +
labs(title = "Reason for Moving to Another State",
x = "Reason",
y = "Count")
# remove rows where WHYMOVE is 0
# and MIGSTA1 is not 91 or 99
# delete columns that are not WHYMOVE and MIGSTA1
data_movers_only <- data |>
filter(WHYMOVE != 0) |>
filter(MIGRATE1 == 5) |>
filter(!(MIGSTA1 == 91 | MIGSTA1 == 99)) |>
select(YEAR, WHYMOVE, MIGSTA1)
ggplot(data_movers_only, aes(x = WHYMOVE)) +
geom_bar() +
labs(title = "Reason for Moving to Another State",
x = "Reason",
y = "Count")
# remove rows where WHYMOVE is 0
# and MIGSTA1 is not 91 or 99
# delete columns that are not WHYMOVE and MIGSTA1
data_movers_only <- data |>
filter(WHYMOVE != 0) |>
filter(MIGRATE1 == 5) |>
filter(!(MIGSTA1 == 91 | MIGSTA1 == 99))
# initial exploring
hist(data$WHYMOVE)
# initial exploring
hist(data$WHYMOVE)
ggplot(data_movers_only, aes(x = WHYMOVE)) +
geom_bar() +
labs(title = "Reason for Moving to Another State",
x = "Reason",
y = "Count")
# remove rows where WHYMOVE is 0
# and MIGSTA1 is not 91 or 99
data_movers_only <- data |>
filter(WHYMOVE != 0) |> # remove NIU cases
filter(MIGRATE1 == 5) |> # filter for movers between states only
filter(!(MIGSTA1 == 91 | MIGSTA1 == 99)) # remove NIU and Same house cases
# histogram of weighted data
ggplot(data_movers_only, aes(x = WHYMOVE, weight = ASECWT)) +
geom_bar() +
labs(title = "Reason for Moving to Another State",
x = "Reason",
y = "Count")
?aes
glimpse(data_movers_only)
# How many people moved for each reason in year 2022?
data_movers_only |>
group_by(WHYMOVE) |>
filter(YEAR == 2022) |>
summarise(count = sum(ASECWT))
data_movers_only |>
group_by(WHYMOVE) |>
filter(YEAR == 2022) |>
summarise(count = n())
data_movers_only |>
group_by(WHYMOVE) |>
# filter(YEAR == 2022) |>
summarise(count = n())
unique(data_movers_only$YEAR)
data_movers_only |>
group_by(WHYMOVE) |>
filter(YEAR %in% (2017, 2018, 2019, 2020, 2022)) |>
data_movers_only |>
group_by(WHYMOVE) |>
filter(YEAR %in% ("2017", "2018", "2019", "2020", "2022")) |>
data_movers_only |>
group_by(WHYMOVE) |>
filter(YEAR %in% c("2017", "2018", "2019", "2020", "2022")) |>
summarise(count = n())
# How many people moved for each reason in year 2022? (weighted)
data_movers_only |>
group_by(WHYMOVE) |>
filter(YEAR == 2022) |>
summarise(count = sum(ASECWT))
# How many people moved for each reason in year 2022? (weighted)
data_movers_only |>
group_by(WHYMOVE, MIGSTA1) |>
filter(YEAR == 2022) |>
summarise(count = sum(ASECWT))
View(data_movers_only |>
group_by(WHYMOVE, MIGSTA1) |>
filter(YEAR == 2022) |>
summarise(count = sum(ASECWT)))
?copy()
movers_copy <- data_movers_only
# How many people moved for each reason by state in year 2022? (weighted)
data_movers_only |>
group_by(YEAR, WHYMOVE, MIGSTA1) |>
summarize(count = sum(ASECWT))
View(data_movers_only |>
group_by(YEAR, WHYMOVE, MIGSTA1) |>
summarize(count = sum(ASECWT)))
write_csv(movers_weighted, "./cleansed data/moving_reason_by_state_weighted.csv")
movers_weighted <-
data_movers_only |>
group_by(YEAR, WHYMOVE, MIGSTA1) |>
summarize(count = sum(ASECWT))
?summarize
# How many people moved for each reason by state in year 2022? (weighted)
data_movers_only |>
group_by(YEAR, WHYMOVE, MIGSTA1) |>
summarize(count = sum(ASECWT)
, .by = c(YEAR, WHYMOVE, MIGSTA1))
# How many people moved for each reason by state in year 2022? (weighted)
data_movers_only |>
summarize(count = sum(ASECWT)
, .by = c(YEAR, WHYMOVE, MIGSTA1))
# movers_weighted <-
data_movers_only |>
group_by(YEAR, WHYMOVE, MIGSTA1) |>
summarize(count = sum(ASECWT))
View(data_movers_only |>
summarize(count = sum(ASECWT)
, .by = c(YEAR, WHYMOVE, MIGSTA1)))
data_movers_only |>
filter(YEAR == 2017
, WHYMOVE == 12
, MIGSTA1 == 25)
1336+454\
1336+454
movers_weighted <-
data_movers_only |>
summarize(count = sum(ASECWT)
, .by = c(YEAR, WHYMOVE, MIGSTA1))
View(movers_weighted)
glimpse(movers_weighted)
movers_weighted$YEAR <- as.character(movers_weighted$YEAR)
movers_weighted$WHYMOVE <- as_factor(movers_weighted$WHYMOVE)
movers_weighted$MIGSTA1 <- as_factor(movers_weighted$MIGSTA1)
glimpse(movers_weighted)
write_csv(movers_weighted, "./cleansed data/moving_reason_by_state_weighted.csv")
devtools::install_github("mark-fangzhou-xie/crimer")
library(crimer)
agencies <- get_url("api/agencies/list")
file.edit("~/.Renviron")
api_key <- Sys.getenv("DATA_GOV_API_KEY")
agencies <- get_url("api/agencies/list")
?get_url
get_agencies()
?get_agencies()
library(crimer)
agencies <- get_url("api/agencies/list")
Sys.getenv()
file.edit("~/.Renviron")
Sys.getenv(DATA_GOV_API_KEY)
Sys.getenv("DATA_GOV_API_KEY")
file.edit("~/.Renviron")
agencies <- get_url("api/agencies/list")
library(crimer)
agencies <- get_url("api/agencies/list")
file.edit("~/.Renviron")
agencies <- get_url("api/agencies/list")
install.packages("crminer")
get_url("api/agencies/list")
library(crimer)
agencies <- get_url("api/agencies/list")
get_url("api/agencies/list")
get_agencies()
get_agency_crime("NY330SS00", since = 1985, until = 2018)
get_agency_crime("NY330SS00", since = 1985, until = 2018)
devtools::install_github("jacobkap/fbi")
library(fbi)
detach("package:crimer", unload = TRUE)
library(fbi)
fbi_api_agencies
knitr::opts_chunk$set(echo = TRUE)
library(fbi)
agencies <- fbi_api_agencies()
agencies <- fbi_api_agencies
View(agencies)
file.edit("~/.Renviron")
set_api_key(sys.getenv("DATA_GOV_API_KEY"))
set_api_key(Sys.getenv("DATA_GOV_API_KEY"))
Sys.getenv("DATA_GOV_API_KEY")
Sys.getenv("DATA_GOV_API_KEY")
Sys.getenv("DATA_GOV_API_KEY")
knitr::opts_chunk$set(echo = TRUE)
set_api_key(Sys.getenv("DATA_GOV_API_KEY"))
library(fbi)
set_api_key(Sys.getenv("DATA_GOV_API_KEY"))
agencies <- fbi_api_agencies
regions
get_estimated_crime("CA")
?get_estimated_crime()
get_estimated_crime("CA", get_api_key())
get_estimated_crime("NY", get_api_key())
ny <- get_estimated_crime("NY")
ny <- get_estimated_crime()
get_nibrs_offense(ori = "DE0010100")
df <- get_nibrs_offense(ori = "DE0010100")
View(df)
View(df)
df[1]
df[[1]]
df[[2]]
df[[3]]
get_nibrs_offense(ori = "DE0010100")
list_nibrs_offenses()
DE0010100 <- get_nibrs_offense(ori = "DE0010100")
DE0010100[1]
DE0010100[2]
DE0010100[3]
DE0010100[4]
DE0010100[5]
DE0010100[6]
DE0010100[7]
DE0010100$content
DE0010100$offense
DE0010100$all_headers
get_nibrs_offense(
key = get_api_key(),
offense = "all",
variable = "count",
ori = NULL,
region = NULL,
state_abb = NULL
)
unique(agencies$agency_type_name)
DE0010100$request
AK0010100 <- get_nibrs_offense(ori = "AK0010100")
AK0010100$request
AK0010100$status_code
AK0010100 <- get_nibrs_offense(ori = "AK0010100", key = get_api_key())
AK0010100$status_code
get_api_key()
install_github("SUN-Wenjun/fbicrime")
devtools::install_github("SUN-Wenjun/fbicrime")
Sys.getenv('DATA_GOV_API_KEY')
library(fbicrime)
set_fbi_crime_api_key(Sys.getenv('DATA_GOV_API_KEY'))
count_offense(offense = 'larceny', level = 'agencies', level_detail = 'MA0010100')
summarize_offender(offense = c('burglary','arson'), level = 'regions', level_detail = c('Northeast','South'), variable = 'sex')
summarize_arrest(by_offense_type = TRUE, offense = c('aggravated-assault','rape'), variable = 'race', since = 2010, until = 2011)
?count_offense
count_offense(offense = 'burglary')
detach("package:fbi", unload = TRUE)
install.packages("tidycensus")
Sys.getenv()
Sys.setenv()
Sys.setenv()
usethis::edit_r_environ()
Sys.getenv("CENSUS_API_KEY")
library(tidycensus)
library(tidyverse)
census_api_key(Sys.getenv("CENSUS_API_KEY"))
install.packages("sf")
census_api_key(Sys.getenv("CENSUS_API_KEY"))
library(tidycensus)
census_api_key(Sys.getenv("CENSUS_API_KEY"))
?get_acs
# Get poverty data for metropolitan areas
poverty_data <- get_acs(geography = "metropolitan statistical area/micropolitan statistical area",
table = "S1901",
survey = "acs1",
year = 2022)
Sys.getenv("CENSUS_API_KEY")
key = Sys.getenv("CENSUS_API_KEY")
census_api_key(key)
# Get poverty data for metropolitan areas
poverty_data <- get_acs(geography = "metropolitan statistical area/micropolitan statistical area",
table = "S1901",
survey = "acs1",
year = 2022)
# Get poverty data for metropolitan areas
poverty_data <- get_acs(geography = "metropolitan statistical area/micropolitan statistical area",
table = "S1901",
survey = "acs1",
year = 2022)
source("~/Documents/GitHub/real-estate-project/scripts/census_poverty_data.R", echo=TRUE)
usethis::edit_r_environ()
key
census_api_key(key)
source("~/Documents/GitHub/real-estate-project/scripts/census_poverty_data.R", echo=TRUE)
# Get poverty data for metropolitan areas
poverty_data <- get_acs(geography = "metropolitan statistical area/micropolitan statistical area",
table = "S1901",
survey = "acs1",
year = 2022)
View(poverty_data)
poverty_data$variable
# Get poverty data for metropolitan areas
poverty_data <- get_acs(geography = "metropolitan statistical area",
table = "S1901",
survey = "acs1",
year = 2022)
unique(poverty_data$variable)
# Create a mapping table
code_mapping <- c(
"S1901_C01_001" = "Total",
"S1901_C01_002" = "Less than $10,000",
"S1901_C01_003" = "$10,000 to $14,999",
"S1901_C01_004" = "$15,000 to $24,999",
"S1901_C01_005" = "$25,000 to $34,999",
"S1901_C01_006" = "$35,000 to $49,999",
"S1901_C01_007" = "$50,000 to $74,999",
"S1901_C01_008" = "$75,000 to $99,999",
"S1901_C01_009" = "$100,000 to $149,999",
"S1901_C01_010" = "$150,000 to $199,999",
"S1901_C01_011" = "$200,000 or more",
"S1901_C01_012" = "Median income (dollars)",
"S1901_C01_013" = "Mean income (dollars)",
"S1901_C01_014" = "Household income in the past 12 months",
"S1901_C01_015" = "Family income in the past 12 months",
"S1901_C01_016" = "Nonfamily income in the past 12 months"
)
# Apply the mapping to your variable
poverty_data$label <- code_mapping[poverty_data$variable]
# Check the result
head(poverty_data[, c("variable", "label")])
# Check the result
head(poverty_data[, c("variable", "label")], 16)
# keep the last three digits of 'variable' in poverty_data
poverty_data$variable <- substr(poverty_data$variable, start = 6, stop = 8)
# keep the last three digits of 'variable' in poverty_data
poverty_data$variable <- substr(poverty_data$variable, start = 11, stop = 13)
# Get poverty data for metropolitan areas
poverty_data <- get_acs(geography = "metropolitan statistical area/micropolitan statistical area",
table = "S1901",
survey = "acs1",
year = 2022)
View(substr(poverty_data$variable, start = 11, stop = 13))
# keep the last three digits of 'variable' in poverty_data
poverty_data$variable <- substr(poverty_data$variable, start = 11, stop = 13)
# Apply the mapping to your variable
poverty_data$label <- code_mapping[poverty_data$variable]
# Check the result
head(poverty_data[, c("variable", "label")], 16)
# Create a mapping table
code_mapping <- c(
"001" = "Total",
"002" = "Less than $10,000",
"003" = "$10,000 to $14,999",
"004" = "$15,000 to $24,999",
"005" = "$25,000 to $34,999",
"006" = "$35,000 to $49,999",
"007" = "$50,000 to $74,999",
"008" = "$75,000 to $99,999",
"009" = "$100,000 to $149,999",
"010" = "$150,000 to $199,999",
"011" = "$200,000 or more",
"012" = "Median income (dollars)",
"013" = "Mean income (dollars)",
"014" = "Household income in the past 12 months",
"015" = "Family income in the past 12 months",
"016" = "Nonfamily income in the past 12 months"
)
# Apply the mapping to your variable
poverty_data$label <- code_mapping[poverty_data$variable]
View(poverty_data %>%
filter(str_detect(NAME, "Micro")))
poverty_data$variable <- NULL
# remove rows with 'Micro' in NAME column
poverty_wo_micro <- poverty_data %>%
filter(!str_detect(NAME, "Micro"))
View(poverty_wo_micro)
?str_detect
# for each value in NAME column, keep the first 13 rows
poverty <- poverty_wo_micro %>%
group_by(NAME) %>%
slice(1:13) %>%
ungroup()
View(poverty)
# for each value in NAME column, sum up the values in 'estimate' column
# from row 2 to row 11
poverty_rate <- poverty %>%
group_by(NAME) %>%
mutate(total = sum(estimate[2:11])) %>%
ungroup()
View(poverty_rate)
# for each value in NAME column, sum up the values in 'estimate' column
# from row 2 to row 11
poverty_rate <- poverty %>%
group_by(NAME) %>%
mutate(total = sum(estimate[2:5])) %>%
ungroup()
# for each value in NAME column, sum up the values in 'estimate' column
# from row 2 to row 11
poverty_rate <- poverty %>%
group_by(NAME) %>%
mutate(total = sum(estimate[2:5]))
# for each value in NAME column, sum up the values in 'estimate' column
# from row 2 to row 11
poverty_rate <- poverty %>%
group_by(NAME) %>%
mutate(total = sum(estimate[2:5]))
# modify the code right above by aggregating the data like in sql
poverty_rate <- poverty %>%
group_by(NAME) %>%
summarise(total = sum(estimate[2:5]))
# modify the code right above by aggregating the data like in sql
poverty_rate <- poverty %>%
group_by(NAME) %>%
summarise(poverty_rate = sum(estimate[2:5]))
# export poverty_rate to a csv file
write_csv(poverty_rate, "../cleansed data/poverty_rate.csv")
# export poverty_rate to a csv file
write_csv(poverty_rate, "./cleansed data/poverty_rate.csv")
